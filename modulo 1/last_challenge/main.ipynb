{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 23)\n",
    "\n",
    "df = pd.read_csv('./recipeData.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73861, 23)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get style of beer if has more than 1000 samples\n",
    "df = df[df['Style'].isin(df['Style'].value_counts()[df['Style'].value_counts() > 1000].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35424, 23)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['BeerID', 'Name', 'URL', 'StyleID', 'UserId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Style             object\n",
       "Size(L)          float64\n",
       "OG               float64\n",
       "FG               float64\n",
       "ABV              float64\n",
       "IBU              float64\n",
       "Color            float64\n",
       "BoilSize         float64\n",
       "BoilTime           int64\n",
       "BoilGravity      float64\n",
       "Efficiency       float64\n",
       "MashThickness    float64\n",
       "SugarScale        object\n",
       "BrewMethod        object\n",
       "PitchRate        float64\n",
       "PrimaryTemp      float64\n",
       "PrimingMethod     object\n",
       "PrimingAmount     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Style                0\n",
       "Size(L)              0\n",
       "OG                   0\n",
       "FG                   0\n",
       "ABV                  0\n",
       "IBU                  0\n",
       "Color                0\n",
       "BoilSize             0\n",
       "BoilTime             0\n",
       "BoilGravity          0\n",
       "Efficiency           0\n",
       "MashThickness        0\n",
       "SugarScale           0\n",
       "BrewMethod           0\n",
       "PitchRate            0\n",
       "PrimaryTemp          0\n",
       "PrimingMethod    32534\n",
       "PrimingAmount    33369\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['PrimingMethod', 'PrimingAmount'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SugarScale'] = df['SugarScale'].map({'Specific Gravity': 0, 'Plato': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['BrewMethod'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['American IPA', 'American Pale Ale', 'Imperial IPA', 'Saison',\n",
       "       'Blonde Ale', 'American Brown Ale', 'American Amber Ale',\n",
       "       'Witbier', 'American Stout', 'Irish Red Ale',\n",
       "       'American Light Lager', 'California Common Beer'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Style'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Style'] = pd.Categorical(df['Style']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Style_encoded'] = le.fit_transform(df['Style'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = df.drop(['Style', 'Style_encoded'], axis=1)\n",
    "y = df['Style_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "0.6158533727939393\n",
      "------------------\n",
      "GradientBoostingClassifier()\n",
      "0.6188738505212379\n",
      "------------------\n",
      "AdaBoostClassifier()\n",
      "0.5450258397366495\n",
      "------------------\n",
      "BaggingClassifier()\n",
      "0.5784211440733179\n",
      "------------------\n",
      "ExtraTreesClassifier()\n",
      "0.5991698409289155\n",
      "------------------\n",
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/leo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/leo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/leo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/leo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4326446349820901\n",
      "------------------\n",
      "DecisionTreeClassifier()\n",
      "0.4735771049851625\n",
      "------------------\n",
      "KNeighborsClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fc823cc2de0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fe3fd5abec0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "^^^^^^^^^    self._make_module_from_path(filepath)\n",
      "^^  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "^^^^^^^^    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "^             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "^^^^^^^^    self.version = self.get_version()\n",
      "^                   ^^^^Exception ignored on calling ctypes callback function^^: ^^^<function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f7050c53f60>^^\n",
      "^Traceback (most recent call last):\n",
      "^^^^  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "^^\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "^^^^^^^^^    config = get_config().split()\n",
      "     ^ ^ ^ ^ ^ ^ ^  \n",
      "     File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      " ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "self._make_module_from_path(filepath)\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "        module = module_class(filepath, prefix, user_api, internal_api)\n",
      " config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f0abdc887c0>\n",
      "Traceback (most recent call last):\n",
      "^  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "^^^^^^^^^^    ^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "self._make_module_from_path(filepath)\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f705bed1440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4868167412961988\n",
      "------------------\n",
      "SVC()\n",
      "0.46756446983411487\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "for model in models: \n",
    "    print(model)\n",
    "    print(cross_val_score(model, X_scaled, y, cv=5, n_jobs=4).mean())\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "  'learning_rate': [0.1, 0.05, 0.01],\n",
    "  'max_depth': [3, 4, 6],\n",
    "  'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=28064212)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', n_jobs=5, cv=5, verbose=1)\n",
    "grid.fit(X_scaled, y)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
